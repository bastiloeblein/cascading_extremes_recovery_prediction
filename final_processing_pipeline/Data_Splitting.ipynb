{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pycountry_convert as pc\n",
    "import kgcpy\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from pyproj import Transformer\n",
    "from scipy.spatial import cKDTree\n",
    "import rioxarray\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv(\"data/1_max_precipitation_grid_cells.csv\", sep = \",\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preparation\n",
    "# Mapping os Labels to season (s. https://zenodo.org/records/13165034)\n",
    "SEASON_LABELS = {\n",
    "    1: \"Winter\",\n",
    "    2: \"Spring\",\n",
    "    3: \"Summer\",\n",
    "    4: \"Autumn\",\n",
    "    5: \"Hotter\",\n",
    "    6: \"Cooler\",\n",
    "    7: \"Dry\",\n",
    "    8: \"Wet\",\n",
    "}\n",
    "\n",
    "# Define file paths \n",
    "season_tif = \"data/WorldSeasons/season.tif\"\n",
    "meta_txt = \"data/WorldSeasons/seasons_data.txt\"\n",
    "\n",
    "# 2. Load and prepare WorldSeasons data\n",
    "df_pheno = pd.read_csv(meta_txt, quotechar='\"', skipinitialspace=True)\n",
    "print(df_pheno.columns)\n",
    "\n",
    "# Initialize transformer\n",
    "season_raster = rioxarray.open_rasterio(season_tif, mask_and_scale=True)\n",
    "raster_wkt = season_raster.rio.crs # get CRS info\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", raster_wkt, always_xy=True)\n",
    "\n",
    "# Build search tree for x,y coordinates\n",
    "coords = df_pheno[['x', 'y']].values\n",
    "tree = cKDTree(coords)\n",
    "\n",
    "# 3. Define function to retrieve phenological season from cooridnates and date\n",
    "def get_pheno_info(row, transformer, tree, df_pheno):\n",
    "    \"\"\"\n",
    "    Extrahiert sowohl die ID als auch den Namen der Saison f√ºr eine Zeile.\n",
    "    \"\"\"\n",
    "    lon = row['longitude']\n",
    "    lat = row['latitude']\n",
    "    date_str = row['end_date']\n",
    "    \n",
    "    # A. Transform lat, lon to meter\n",
    "    x_m, y_m = transformer.transform(lon, lat)\n",
    "    \n",
    "    # B. Search for closest match\n",
    "    dist, idx = tree.query([x_m, y_m])\n",
    "    pheno_row = df_pheno.iloc[idx]\n",
    "    \n",
    "    # C. Get month from date \n",
    "    date_obj = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    month_name = date_obj.strftime(\"%B\")\n",
    "    \n",
    "    # D. Get Label ID\n",
    "    label_id = int(pheno_row[month_name])\n",
    "    \n",
    "    # E. Mapping anwenden\n",
    "    season_name = SEASON_LABELS.get(label_id, \"Unknown\")\n",
    "    \n",
    "    return pd.Series([label_id, season_name])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continent_from_iso(iso_code):\n",
    "    try:\n",
    "        iso_alpha2 = pc.country_alpha3_to_country_alpha2(iso_code)\n",
    "        continent_code = pc.country_alpha2_to_continent_code(iso_alpha2)\n",
    "        continent_name = pc.convert_continent_code_to_continent_name(continent_code)\n",
    "        return continent_name\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def get_country_from_iso(iso_code):\n",
    "    try:\n",
    "        iso_alpha2 = pc.country_alpha3_to_country_alpha2(iso_code)\n",
    "        country_name = pc.country_alpha2_to_country_name(iso_alpha2)\n",
    "        return country_name\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def add_metadata_to_cubes(df):\n",
    "    print(\"üöÄ Start Metadata extrakcion...\")\n",
    "\n",
    "    ts = api.load.timescale()\n",
    "    eph = api.load('de421.bsp')\n",
    "\n",
    "    # 1. Kontinent hinzuf√ºgen\n",
    "    df['continent'] = df['iso'].apply(get_continent_from_iso)\n",
    "    df['country'] = df['iso'].apply(get_country_from_iso)\n",
    "    df[['pheno_label_id', 'pheno_season_name']] = df.apply(\n",
    "        lambda row: get_pheno_info(row, transformer, tree, df_pheno), \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # 2. Define K√∂ppen-Geiger Climate zone\n",
    "    # kgp uses global grid, to find the respective zone based on lat/lon\n",
    "    print(\"üåç Bestimme Klimazonen (K√∂ppen-Geiger)...\")\n",
    "    \n",
    "    # Extract all zones for rows in df\n",
    "    zones = []\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            zone = kgcpy.lookupCZ(row['latitude'], row['longitude'])\n",
    "            zones.append(zone)\n",
    "        except:\n",
    "            zones.append(\"Unknown\")\n",
    "    \n",
    "    df['koppen_geiger'] = zones\n",
    "\n",
    "    # 3. Derive more coarse climate class (first letter of Koppen-Geiger Zone)\n",
    "    # (A=Tropic, B=Arid, C=Warm-termperate, D=Cold, E=Polar)\n",
    "    df['climate_class'] = df['koppen_geiger'].str[0]\n",
    "\n",
    "    start_cols = ['DisNo.', 'iso', 'country', 'continent', 'climate_class', 'koppen_geiger', 'pheno_label_id', 'pheno_season_name',  'latitude', 'longitude', 'start_date', 'end_date']\n",
    "\n",
    "    df = df[start_cols + [c for c in df.columns if c not in start_cols]]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = add_metadata_to_cubes(df)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "train_idx, test_idx = train_test_split(\n",
    "    df.index, \n",
    "    test_size=0.20, \n",
    "    random_state=42,    \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "df_final = df.copy()\n",
    "\n",
    "# Create column for split\n",
    "df_final[\"split\"] = \"train\"\n",
    "\n",
    "# Set test indices to test\n",
    "df_final.loc[test_idx, 'split'] = 'test'\n",
    "\n",
    "# Check\n",
    "print(df_final['split'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = df_final[df_final[\"split\"] == \"train\"]\n",
    "ds_test = df_final[df_final[\"split\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test_split(ds_train, ds_test, column_to_plot):\n",
    "    \"\"\"\n",
    "    Plots Train and Test sets side-by-side with synchronized colors for the given column.\n",
    "    \"\"\"\n",
    "    # 1. Load world map\n",
    "    url = \"https://naciscdn.org/naturalearth/110m/cultural/ne_110m_admin_0_countries.zip\"\n",
    "    world = gpd.read_file(url)\n",
    "\n",
    "    # 2. Create a consistent color map for all unique values in the column\n",
    "    all_values = pd.concat([ds_train[column_to_plot], ds_test[column_to_plot]]).unique()\n",
    "    unique_values = sorted([v for v in all_values if pd.notna(v)])\n",
    "    \n",
    "    # Using 'tab20' for distinct colors; scales automatically to the number of unique values\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(unique_values)))\n",
    "    color_dict = dict(zip(unique_values, colors))\n",
    "\n",
    "    # 3. Convert to GeoDataFrames\n",
    "    gdf_train = gpd.GeoDataFrame(\n",
    "        ds_train, geometry=gpd.points_from_xy(ds_train.longitude, ds_train.latitude), crs=\"EPSG:4326\")\n",
    "    gdf_test = gpd.GeoDataFrame(\n",
    "        ds_test, geometry=gpd.points_from_xy(ds_test.longitude, ds_test.latitude), crs=\"EPSG:4326\")\n",
    "\n",
    "    # 4. Setup Plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(25, 10), sharex=True, sharey=True)\n",
    "    bg_settings = {'color': '#eeeeee', 'edgecolor': '#bcbcbc'}\n",
    "    marker_size = 50\n",
    "\n",
    "    # Helper to plot each category to ensure legend and color consistency\n",
    "    def plot_subset(ax, gdf, title):\n",
    "        world.plot(ax=ax, **bg_settings)\n",
    "        for val, color in color_dict.items():\n",
    "            mask = gdf[column_to_plot] == val\n",
    "            if mask.any():\n",
    "                gdf[mask].plot(ax=ax, color=color, label=val, markersize=marker_size)\n",
    "        ax.legend(title=column_to_plot, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        ax.set_title(f\"{title} (n={len(gdf)})\", fontsize=16)\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.grid(alpha=0.2)\n",
    "\n",
    "    # Execute plotting\n",
    "    plot_subset(ax1, gdf_train, f\"Training Set: {column_to_plot}\")\n",
    "    plot_subset(ax2, gdf_test, f\"Test Set: {column_to_plot}\")\n",
    "\n",
    "    fig.supxlabel('Longitude')\n",
    "    fig.supylabel('Latitude')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Example Usage ---\n",
    "plot_train_test_split(ds_train, ds_test, 'koppen_geiger')\n",
    "plot_train_test_split(ds_train, ds_test, 'climate_class')\n",
    "plot_train_test_split(ds_train, ds_test, 'pheno_season_name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_vars = ['BARE', 'BUILT', 'GRASS-MAN', 'GRASS-NAT', 'SHRUBS', 'TREES', 'WATER']\n",
    "\n",
    "# Sicherstellen, dass end_date ein datetime-Objekt ist\n",
    "df_final['end_date'] = pd.to_datetime(df_final['end_date'])\n",
    "\n",
    "# Jahr und Monat extrahieren\n",
    "df_final['year'] = df_final['end_date'].dt.year\n",
    "df_final['month'] = df_final['end_date'].dt.month\n",
    "\n",
    "# Setze ein sauberes Design\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# 1. Histogramm/Balkendiagramm f√ºr Climate Classes\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Wir sortieren die Klassen (A, B, C, D, E) f√ºr eine bessere Lesbarkeit\n",
    "order = sorted(df_final['climate_class'].unique())\n",
    "sns.countplot(data=df_final, x='climate_class', hue='split', order=order, palette='viridis')\n",
    "plt.title('Distribution of climate classes over train and test')\n",
    "plt.ylabel('Number of Cubes')\n",
    "plt.legend(title='Split Set')\n",
    "\n",
    "# 2. Balkendiagramm f√ºr Kontinente\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Sortierung nach H√§ufigkeit im Gesamtdatensatz\n",
    "continent_order = df_final['continent'].value_counts().index\n",
    "sns.countplot(data=df_final, x='continent', hue='split', order=continent_order, palette='magma')\n",
    "plt.title('Distribution of continents over train and test')\n",
    "plt.ylabel('Number of Cubes')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Split Set')\n",
    "\n",
    "# 3. Histogramm f√ºr tp_rollingmax (Numerisch)\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Wir nutzen ein Histogramm mit KDE (Dichtesch√§tzung), um die Verteilung zu vergleichen\n",
    "sns.histplot(data=df_final, x='tp_rollingmax', hue='split', kde=True, element=\"step\", common_norm=False, palette='rocket')\n",
    "plt.title('Distribution of rolling max (max. precipitation) over  train and test')\n",
    "plt.xlabel('Max Precipitation')\n",
    "plt.ylabel('Number of Cubes')\n",
    "\n",
    "\n",
    "# 3. Histogramm f√ºr tp_rollingmax (Numerisch)\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Wir nutzen ein Histogramm mit KDE (Dichtesch√§tzung), um die Verteilung zu vergleichen\n",
    "sns.histplot(data=df_final, x='year', hue='split', kde=True, element=\"step\", common_norm=False, palette='rocket')\n",
    "plt.title('Temporal Distribution')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Cubes')\n",
    "\n",
    "# 5. Histogramm √ºber Monate\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Monate von 1 bis 12 sortieren\n",
    "sns.countplot(data=df_final, x='pheno_season_name', hue='split', palette='magma')\n",
    "plt.title('Pheno seasonal distribution')\n",
    "plt.xlabel('Seasom')\n",
    "plt.ylabel('Number of Cubes')\n",
    "plt.legend(title='Split Set')\n",
    "\n",
    "for var in lc_vars:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Da dies numerische Werte innerhalb deiner 1000x1000 Cubes sind, \n",
    "    # zeigt ein histplot die Verteilung der Fl√§chenanteile am besten.\n",
    "    sns.histplot(\n",
    "        data=df_final, \n",
    "        x=var, \n",
    "        hue='split', \n",
    "        kde=True, \n",
    "        element=\"step\", \n",
    "        common_norm=False, \n",
    "        palette='viridis'\n",
    "    )\n",
    "    \n",
    "    plt.title(f'Verteilung der Landbedeckung: {var}')\n",
    "    plt.xlabel(f'{var} Anteil/Fl√§che')\n",
    "    plt.ylabel('Anzahl der Cubes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_cols = ['DisNo.', 'split', 'iso', 'country', 'continent', 'climate_class', 'koppen_geiger', 'pheno_label_id', 'pheno_season_name','latitude', 'longitude', 'start_date', 'end_date']\n",
    "df_final = df_final[start_cols + [c for c in df_final.columns if c not in start_cols]]\n",
    "df_final.to_csv(\"data/train_test_split.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
