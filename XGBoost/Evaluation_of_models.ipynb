{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib          \n",
    "import pandas as pd        \n",
    "import numpy as np         \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from typing import Dict \n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.evaluation import *\n",
    "import os\n",
    "import xarray as xr\n",
    "# import xgboost as xgb      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LC_MAPPING: Dict[int, str] = {\n",
    "    10: 'Tree cover',             # Dunkelgrün\n",
    "    20: 'Shrubland',              # Helleres Grün\n",
    "    30: 'Grassland',              # Helles leuchtendes Grün\n",
    "    40: 'Cropland',               # Bräunlich/Beige\n",
    "    50: 'Built-up',               # Dunkelgrau\n",
    "    60: 'Bare/Sparse vegetation', # Mittelgrau\n",
    "    70: 'Snow and ice',           # Sehr helles Weißblau\n",
    "    80: 'Permanent water bodies', # Kräftiges Blau\n",
    "    90: 'Herbaceous wetland',     # Mittelgrün\n",
    "    100: 'Moss and lichen',       # Silber/Grau\n",
    "    1: 'Unknown/No Data',          # Weiß\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Define test data and target var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_keys = [\"ds_5\", \"ds_10\"]\n",
    "target_var = \"target_basic\"\n",
    "ndvi_input = \"NDVI_baisc_t\"\n",
    "\n",
    "path = \"../processed_data_final/\"\n",
    "cubes = {}\n",
    "\n",
    "for key in test_keys:\n",
    "    load_path = os.path.join(path,key)\n",
    "    cubes[key] = xr.open_zarr(load_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_master = pd.read_parquet(f\"new_data/master_test_combined.parquet\").dropna(subset=[target_var]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Modelle evaluieren\n",
    "model_dir = \"sar_experiments/\"\n",
    "models = [m for m in os.listdir(model_dir) if m.endswith(\".pkl\")]\n",
    "all_model_results = []\n",
    "ts_metrics_storage = {}\n",
    "\n",
    "# models = [\"Model_Basic_Baseline SAR.pkl\", \"Model_Basic_Baseline Spectral.pkl\", \"Model_Basic_Temp_Only_with_Lags.pkl\",\"Model_Basic_Temp_Only.pkl\" ,\"Model_Basic_Water_Only.pkl\", \"Model_Basic_Water_Only_with_Lags.pkl\", \"Model_Basic_Full_Climate.pkl\"]\n",
    "\n",
    "for model_file in models:\n",
    "    pkg = joblib.load(os.path.join(model_dir, model_file))\n",
    "    model, feats, m_name, target_v = pkg[\"model\"], pkg[\"features\"], pkg[\"model_name\"] , pkg[\"target_variable\"]\n",
    "    ndvi_in = \"NDVI_basic_t\" if \"basic\" in target_v else \"NDVI_strict_t\"\n",
    "\n",
    "    print(\"##\"*12)\n",
    "    print(f\"Modell '{m_name}' erfolgreich geladen.\")\n",
    "    print(f\"Features im Modell: {feats}\")\n",
    "\n",
    "    # Prediction\n",
    "    X_eval = df_test_master[feats].copy()\n",
    "    if \"lc_class\" in X_eval.columns: X_eval[\"lc_class\"] = X_eval[\"lc_class\"].astype(\"category\")\n",
    "    df_test_master[\"preds\"] = model.predict(X_eval)\n",
    "    valid_res = df_test_master.dropna(subset=[target_v]).copy()\n",
    "\n",
    "    # Metriken berechnen\n",
    "    global_m = get_metrics(valid_res, target_v)\n",
    "    m_clear, m_cloudy = evaluate_with_gap_analysis(valid_res, target_v, ndvi_in)\n",
    "    \n",
    "    # Recovery Analyse (Aggregiert über Test Cubes)\n",
    "    recovery_list = []\n",
    "    for k in test_keys:\n",
    "        precip_dt = pd.to_datetime(cubes[k].precip_end_date)\n",
    "        t_times = pd.to_datetime(cubes[k].time_sentinel_2_l2a.values)\n",
    "        in_idx = np.where(t_times <= precip_dt)[0][-1]\n",
    "        recovery_list.append(valid_res[(valid_res['cube_origin'] == k) & (valid_res['timestep'] == in_idx)])\n",
    "    \n",
    "    m_recov = get_metrics(pd.concat(recovery_list), target_v)\n",
    "    \n",
    "    # Zeitverlauf speichern\n",
    "    if m_name not in ts_metrics_storage:\n",
    "        ts_metrics_storage[m_name] = {}\n",
    "\n",
    "    for k in test_keys:\n",
    "        # Berechne Metriken nur für diesen spezifischen Cube\n",
    "        cube_res = valid_res[valid_res['cube_origin'] == k]\n",
    "        if len(cube_res) > 0:\n",
    "            ts_metrics_storage[m_name][k] = cube_res.groupby(\"timestep\").apply(lambda x: get_metrics(x, target_v))\n",
    "\n",
    "    # Print-Ausgabe\n",
    "    print(f\"\\n▶ {m_name.upper()} | Target: {target_v}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\" GLOBALE ERGEBNISSE: {m_name}\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Anzahl Pixel: {global_m['Count']}\")\n",
    "    print(f\"RMSE:         {global_m['RMSE']:.4f}\")\n",
    "    print(f\"MAE:          {global_m['MAE']:.4f}\")\n",
    "    print(f\"Bias:         {global_m['Bias']:.4f}\")\n",
    "\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"\\n--- GAP ANALYSIS: {m_name} ---\")\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"CLEAR SKY (NDVI_t vorhanden):  RMSE: {m_clear['RMSE']:.4f} MAE: {m_clear['MAE']:.4f} (n={int(m_clear['Count'])})\")\n",
    "    print(f\"CLOUDY    (Radar-Only):        RMSE: {m_cloudy['RMSE']:.4f} MAE: {m_cloudy['MAE']:.4f} (n={int(m_cloudy['Count'])})\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\" RECOVERY: {m_name}\")\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"Anzahl Pixel: {m_recov['Count']}\")\n",
    "    print(f\"RMSE:         {m_recov['RMSE']:.4f}\")\n",
    "    print(f\"MAE:          {m_recov['MAE']:.4f}\")\n",
    "    print(f\"Bias:         {m_recov['Bias']:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    # print(f\"  GLOBAL:    RMSE: {global_m['RMSE']:.4f} | Bias: {global_m['Bias']:.4f} \\n\")\n",
    "    # print(f\"  RECOVERY:  RMSE: {m_recov['RMSE']:.4f} (Moment nach Regen) \\n\")\n",
    "    # print(f\"  GAP:       Clear: {m_clear['RMSE']:.4f} | Cloudy: {m_cloudy['RMSE']:.4f} \\n\")\n",
    "\n",
    "\n",
    "    fi_results = plot_feature_importance(pkg)\n",
    "\n",
    "\n",
    "    all_model_results.append({\n",
    "        \"Model\": m_name, \"Target\": target_v, \"RMSE_Global\": global_m[\"RMSE\"],\n",
    "        \"RMSE_Recovery\": m_recov[\"RMSE\"], \"RMSE_Cloudy\": m_cloudy[\"RMSE\"]\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(all_model_results).sort_values(\"RMSE_Global\")\n",
    "display(df_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparison.to_csv(\"sar_experiments/model_comparison_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparison.sort_values(\"RMSE_Global\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_sar_correlation(df):\n",
    "    # 1. Auswahl der relevanten SAR-Spalten\n",
    "    sar_cols = ['vv', 'vh', 'VHVVR', 'VVVHS', 'DpRVIVV', \"target_basic\", \"target_strict\"]\n",
    "    \n",
    "    # Sicherstellen, dass nur vorhandene Spalten genutzt werden\n",
    "    existing_cols = [c for c in sar_cols if c in df.columns]\n",
    "    \n",
    "    # 2. Korrelation berechnen (Pearson)\n",
    "    corr_matrix = df[existing_cols].corr()\n",
    "\n",
    "    # 3. Plotten\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0, vmin=-1, vmax=1, fmt='.2f')\n",
    "    plt.title(\"Korrelation zwischen SAR-Bändern und Indizes\", fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "# Anwendung auf dein Test-Set oder Training-Set\n",
    "plot_sar_correlation(df_test_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_temporal_performance_per_cube(cubes, ts_metrics_storage, metric=\"RMSE\"):\n",
    "    test_keys = list(cubes.keys())\n",
    "    \n",
    "    for k in test_keys:\n",
    "        ds = cubes[k]\n",
    "        fig, ax = plt.subplots(figsize=(14, 6))\n",
    "        \n",
    "        # Zeitachse vorbereiten (Mapping von ID zu Datum)\n",
    "        t_times = pd.to_datetime(ds.time_sentinel_2_l2a.values)\n",
    "        \n",
    "        # Für jedes Modell die Linie zeichnen\n",
    "        for m_name in ts_metrics_storage.keys():\n",
    "            if k in ts_metrics_storage[m_name]:\n",
    "                stats = ts_metrics_storage[m_name][k]\n",
    "                # Wir mappen die Timestep-Indizes auf die echten Daten\n",
    "                plot_dates = t_times[stats.index.values]\n",
    "                ax.plot(plot_dates, stats[metric], label=m_name, marker='o', markersize=4, alpha=0.8)\n",
    "\n",
    "        # Perioden aus dem Cube holen\n",
    "        start_d = pd.to_datetime(ds.attrs[\"drought_start_date\"])\n",
    "        end_d = pd.to_datetime(ds.attrs[\"drought_end_date\"])\n",
    "        start_p = pd.to_datetime(ds.attrs[\"precip_start_date\"])\n",
    "        end_p = pd.to_datetime(ds.attrs[\"precip_end_date\"])\n",
    "\n",
    "        # Perioden farblich markieren\n",
    "        ax.axvspan(start_d, end_d, color=\"red\", alpha=0.1, label=\"Dürre-Periode\")\n",
    "        ax.axvspan(start_p, end_p, color=\"blue\", alpha=0.1, label=\"Regen-Periode\")\n",
    "\n",
    "        # Styling\n",
    "        ax.set_title(f\"Performance Verlauf für Cube: {k}\", fontsize=15, fontweight='bold')\n",
    "        ax.set_ylabel(f\"{metric} (niedriger ist besser)\")\n",
    "        ax.set_xlabel(\"Datum\")\n",
    "        ax.grid(True, alpha=0.2)\n",
    "        ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Aufruf\n",
    "plot_temporal_performance_per_cube(cubes, ts_metrics_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def plot_detailed_model_performance(cubes, ts_metrics_storage):\n",
    "    \"\"\"\n",
    "    Erstellt pro Modell eine Abbildung mit Subplots für jeden Cube.\n",
    "    Zeigt RMSE und Bias im Zeitverlauf mit Durchschnittslinien.\n",
    "    \"\"\"\n",
    "    metrics = [\"RMSE\", \"Bias\"]\n",
    "    \n",
    "    for m_name in ts_metrics_storage.keys():\n",
    "        current_model_data = ts_metrics_storage[m_name]\n",
    "        n_cubes = len(current_model_data)\n",
    "        \n",
    "        # Erstelle Grid: Zeilen = Metriken, Spalten = Cubes\n",
    "        fig, axes = plt.subplots(len(metrics), n_cubes, figsize=(7 * n_cubes, 10), sharey='row')\n",
    "        fig.suptitle(f\"DETAILLIERTE ANALYSE: {m_name.upper()}\", fontsize=18, fontweight='bold', y=1.02)\n",
    "\n",
    "        for col_idx, (cube_key, stats) in enumerate(current_model_data.items()):\n",
    "            ds = cubes[cube_key]\n",
    "            t_times = pd.to_datetime(ds.time_sentinel_2_l2a.values)\n",
    "            plot_dates = t_times[stats.index.values]\n",
    "            \n",
    "            # Event-Daten\n",
    "            events = {\n",
    "                \"Dürre\": (pd.to_datetime(ds.attrs[\"drought_start_date\"]), \n",
    "                          pd.to_datetime(ds.attrs[\"drought_end_date\"]), \"red\"),\n",
    "                \"Regen\": (pd.to_datetime(ds.attrs[\"precip_start_date\"]), \n",
    "                          pd.to_datetime(ds.attrs[\"precip_end_date\"]), \"blue\")\n",
    "            }\n",
    "\n",
    "            for row_idx, metric in enumerate(metrics):\n",
    "                # Handle Fall für nur einen Cube (axes ist dann 1D)\n",
    "                ax = axes[row_idx, col_idx] if n_cubes > 1 else axes[row_idx]\n",
    "                \n",
    "                # 1. Zeitverlauf plotten\n",
    "                ax.plot(plot_dates, stats[metric], marker='o', markersize=3, label=f\"{metric} Verlauf\")\n",
    "                \n",
    "                # 2. Durchschnittslinie hinzufügen\n",
    "                mean_val = stats[metric].mean()\n",
    "                ax.axhline(mean_val, color='darkorange', linestyle='--', linewidth=2, \n",
    "                           label=f\"Ø-{metric}: {mean_val:.4f}\")\n",
    "                \n",
    "                # 3. Referenzlinie für Bias bei 0\n",
    "                if metric == \"Bias\":\n",
    "                    ax.axhline(0, color='black', linewidth=1, alpha=0.5)\n",
    "\n",
    "                # 4. Phasen markieren\n",
    "                for label, (start, end, color) in events.items():\n",
    "                    ax.axvspan(start, end, color=color, alpha=0.1)\n",
    "\n",
    "                # Styling\n",
    "                if row_idx == 0:\n",
    "                    ax.set_title(f\"Cube: {cube_key}\", fontsize=14, fontweight='bold')\n",
    "                if col_idx == 0:\n",
    "                    ax.set_ylabel(metric, fontsize=12, fontweight='bold')\n",
    "                \n",
    "                ax.grid(True, alpha=0.2)\n",
    "                ax.legend(loc='best', fontsize='small')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Anwendung\n",
    "plot_detailed_model_performance(cubes, ts_metrics_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"models_new/\"\n",
    "models = os.listdir(model_dir)\n",
    "for model in models:\n",
    "\n",
    "    model_name  = model.split(\".\")[0]\n",
    "\n",
    "    # Get model and info\n",
    "    model_path = os.path.join(model_dir, model)\n",
    "    model_package = joblib.load(model_path)\n",
    "    model = model_package[\"model\"]\n",
    "    features_from_model = model_package[\"features\"]\n",
    "    model_name = model_package[\"model_name\"]\n",
    "\n",
    "    print(\"##\"*12)\n",
    "    print(f\"Modell '{model_name}' erfolgreich geladen.\")\n",
    "    print(f\"Features im Modell: {features_from_model}\")\n",
    "\n",
    "    # Restrict to relevant features\n",
    "    X_eval = df_eval[features_from_model].copy()\n",
    "\n",
    "    # Explicitly convert lc_class to category\n",
    "    if \"lc_class\" in X_eval.columns:\n",
    "        X_eval[\"lc_class\"] = X_eval[\"lc_class\"].astype(\"category\")\n",
    "\n",
    "    # Prediction\n",
    "    df_eval[\"preds\"] = model.predict(X_eval)\n",
    "\n",
    "    # Drop all lines where target_var is NAN\n",
    "    valid_results = df_eval.dropna(subset=[target_var]).copy()\n",
    "\n",
    "    # Map lc_class to LC name\n",
    "    valid_results['LC_Name'] = valid_results['lc_class'].map(LC_MAPPING)\n",
    "\n",
    "    print(f\"Prediction abgeschlossen. Evaluierung auf {len(valid_results):,} validen Zielwerten.\")\n",
    "\n",
    "\n",
    "    # Globale Metriken\n",
    "    global_stats = get_metrics(valid_results)\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\" ERGEBNISSE: {model_name}\")\n",
    "    print(\"=\"*40)\n",
    "    print(global_stats.to_string())\n",
    "    \n",
    "    # Nach Landcover\n",
    "    lc_stats = valid_results.groupby(\"LC_Name\", observed=True).apply(get_metrics)\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\" NACH LANDCOVER-KLASSE\")\n",
    "    print(\"=\"*40)\n",
    "    print(lc_stats.to_string())\n",
    "\n",
    "\n",
    "    # Get metrics for cloudy vs clear input\n",
    "    stats_clear, stats_cloudy = evaluate_with_gap_analysis(valid_results, model_name)\n",
    "\n",
    "    fi_results = plot_feature_importance(model_package)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(df):\n",
    "    y_true = df[target_var]\n",
    "    y_pred = df[\"preds\"]\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    bias = np.mean(y_pred - y_true)\n",
    "    return pd.Series({\"RMSE\": rmse, \"MAE\": mae, \"Bias\": bias, \"Count\": len(df)})\n",
    "\n",
    "# Globale Metriken\n",
    "global_stats = get_metrics(valid_results)\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\" ERGEBNISSE: {model_name}\")\n",
    "print(\"=\"*40)\n",
    "print(global_stats.to_string())\n",
    "\n",
    "# Nach Landcover\n",
    "lc_stats = valid_results.groupby(\"LC_Name\", observed=True).apply(get_metrics)\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\" NACH LANDCOVER-KLASSE\")\n",
    "print(\"=\"*40)\n",
    "print(lc_stats.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_gap_analysis(df_results, model_label=\"Model\"):\n",
    "    # Hilfsfunktion für Metriken (falls noch nicht global definiert)\n",
    "    def calculate_stats(df):\n",
    "        if len(df) == 0: return pd.Series({\"RMSE\": np.nan, \"MAE\": np.nan, \"Bias\": np.nan, \"Count\": 0})\n",
    "        y_true, y_pred = df[target_var], df[\"preds\"]\n",
    "        return pd.Series({\n",
    "            \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "            \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "            \"Bias\": np.mean(y_pred - y_true),\n",
    "            \"Count\": int(len(df))\n",
    "        })\n",
    "\n",
    "    # Filter auf Zeilen mit Target (sonst kein Fehler berechenbar)\n",
    "    df_clean = df_results.dropna(subset=[target_var]).copy()\n",
    "\n",
    "    # Split\n",
    "    m_clear = calculate_stats(df_clean[df_clean[ndvi_input].notna()])\n",
    "    m_cloudy = calculate_stats(df_clean[df_clean[ndvi_input].isna()])\n",
    "\n",
    "    # Schöner Output\n",
    "    print(f\"\\n--- GAP ANALYSIS: {model_label} ---\")\n",
    "    print(f\"CLEAR SKY (NDVI_t vorhanden):  RMSE: {m_clear['RMSE']:.4f} (n={int(m_clear['Count'])})\")\n",
    "    print(f\"CLOUDY    (Radar-Only):        RMSE: {m_cloudy['RMSE']:.4f} (n={int(m_cloudy['Count'])})\")\n",
    "    \n",
    "    return m_clear, m_cloudy\n",
    "\n",
    "# Aufruf\n",
    "stats_clear, stats_cloudy = evaluate_with_gap_analysis(valid_results, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_feature_importance(model_package, top_n=20):\n",
    "    \"\"\"\n",
    "    Plottet die Feature Importance in absteigender Reihenfolge und \n",
    "    gibt die exakten Werte als Tabelle aus.\n",
    "    \"\"\"\n",
    "    model = model_package[\"model\"]\n",
    "    features = model_package[\"features\"]\n",
    "    model_name = model_package.get(\"model_name\", \"Model\")\n",
    "\n",
    "    # Importance aus dem XGBRegressor extrahieren\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    # DataFrame erstellen und sortieren\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance_Gain': importances\n",
    "    }).sort_values(by='Importance_Gain', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # 1. Plotten\n",
    "    plt.figure(figsize=(10, 0.4 * min(len(fi_df), top_n) + 2))\n",
    "    ax = sns.barplot(\n",
    "        x='Importance_Gain', \n",
    "        y='Feature', \n",
    "        data=fi_df.head(top_n), \n",
    "        palette='magma',\n",
    "        hue='Feature',\n",
    "        legend=False\n",
    "    )\n",
    "    \n",
    "    # Werte direkt an die Balken schreiben\n",
    "    for p in ax.patches:\n",
    "        width = p.get_width()\n",
    "        ax.text(width + 0.002, p.get_y() + p.get_height()/2, \n",
    "                f'{width:.4f}', va='center', fontsize=10)\n",
    "\n",
    "    plt.title(f'Feature Importance (Sorted by Gain) - {model_name}', fontsize=14)\n",
    "    plt.xlabel('Normalized Importance Score')\n",
    "    plt.ylabel('Features')\n",
    "    plt.xlim(0, fi_df['Importance_Gain'].max() * 1.15) # Platz für Text rechts\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Tabellarische Ausgabe\n",
    "    print(f\"\\n--- Feature Importance Liste: {model_name} ---\")\n",
    "    print(fi_df.head(top_n).to_string(index=False, formatters={'Importance_Gain': '{:,.4f}'.format}))\n",
    "    \n",
    "    return fi_df\n",
    "\n",
    "# Anwendung:\n",
    "fi_results = plot_feature_importance(model_package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = \"../processed_data/\"\n",
    "data_dir = os.listdir(path_dir)\n",
    "print(data_dir)\n",
    "\n",
    "cubes = {}\n",
    "\n",
    "for path in data_dir:\n",
    "    key = path[5:9]\n",
    "    load_path = os.path.join(path_dir, path)\n",
    "    cubes[key] = xr.open_zarr(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_post_precip_recovery(df_results, ds_test):\n",
    "    # 1. Das precip_end_date aus dem Cube holen und konvertieren\n",
    "    # Wir nehmen an, es ist ein einzelner Wert oder wir nehmen den ersten\n",
    "    precip_end_dt = pd.to_datetime(ds_test.precip_end_date)\n",
    "    if isinstance(precip_end_dt, pd.DatetimeIndex):\n",
    "        precip_end_dt = precip_end_dt[0]\n",
    "        \n",
    "    print(f\"Referenzdatum (Regenende): {precip_end_dt.date()}\")\n",
    "\n",
    "    # 2. Die Zeitstempel-Liste aus dem Cube holen\n",
    "    # Damit können wir die 'timestep' ID (0, 1, 2...) wieder in echte Daten umwandeln\n",
    "    test_times = pd.to_datetime(ds_test.time_sentinel_2_l2a.values)\n",
    "    \n",
    "    # 3. Den Index finden, der am nächsten am precip_end_dt liegt (aber davor oder am selben Tag)\n",
    "    # Das ist der Tag, an dem wir die Features messen (Input t)\n",
    "    input_idx = np.where(test_times <= precip_end_dt)[0][-1]\n",
    "    \n",
    "    # Das Ziel (Target) ist der nächste verfügbare Zeitschritt (t+1)\n",
    "    target_idx = input_idx + 1\n",
    "    \n",
    "    print(f\"Input Timestep ID: {input_idx} (Datum: {test_times[input_idx].date()})\")\n",
    "    print(f\"Target Timestep ID: {target_idx} (Datum: {test_times[target_idx].date()})\")\n",
    "\n",
    "    # 4. In valid_results genau diese Zeitschritte filtern\n",
    "    # Wir suchen Zeilen, wo 'timestep' dem input_idx entspricht\n",
    "    # (Da unser df so gebaut ist, dass bei timestep i der Input i und das Target i+1 ist)\n",
    "    recovery_df = df_results[df_results['timestep'] == input_idx].copy()\n",
    "\n",
    "    if recovery_df.empty:\n",
    "        print(\"Warnung: Keine Daten für diesen spezifischen Zeitschritt gefunden!\")\n",
    "        return None\n",
    "\n",
    "    # 5. Metriken für diesen speziellen Moment berechnen\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "    \n",
    "    y_true = recovery_df[\"target_basic\"]\n",
    "    y_pred = recovery_df[\"preds\"]\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    bias = np.mean(y_pred - y_true)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"PERFORMANCE DIREKT NACH REGENENDE\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Anzahl Pixel: {len(recovery_df)}\")\n",
    "    print(f\"RMSE:         {rmse:.4f}\")\n",
    "    print(f\"MAE:          {mae:.4f}\")\n",
    "    print(f\"Bias:         {bias:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return recovery_df, input_idx\n",
    "\n",
    "# Anwendung\n",
    "# valid_results muss aus deiner vorherigen Evaluation stammen\n",
    "df_recovery, input_idx = evaluate_post_precip_recovery(valid_results, cubes[test_key])\n",
    "\n",
    "print(\"I checked: The day before precip_end_date is completely clouded\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Erstelle eine Figur mit zwei Unterplots (1 Zeile, 2 Spalten)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 1. Linker Plot: Letzter Zeitstempel vor/am Regenende (Input)\n",
    "input_date = pd.to_datetime(cubes[test_key].time_sentinel_2_l2a.values[input_idx]).date()\n",
    "cubes[test_key].NDVI_basic.isel(time_sentinel_2_l2a=input_idx).plot(ax=ax1, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "ax1.set_title(f\"Input: Vor/am Regenende\\n({input_date})\")\n",
    "\n",
    "# 2. Rechter Plot: Erster Zeitstempel nach Regenende (Target)\n",
    "target_date = pd.to_datetime(cubes[test_key].time_sentinel_2_l2a.values[input_idx + 1]).date()\n",
    "cubes[test_key].NDVI_basic.isel(time_sentinel_2_l2a=input_idx + 1).plot(ax=ax2, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "ax2.set_title(f\"Target: Nach Regenende\\n({target_date})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_error_heatmap(df_eval, ds_test):\n",
    "    # 1. Timesteps den echten Monaten zuordnen\n",
    "    # Wir holen die Zeitstempel aus dem ursprünglichen Test-Cube\n",
    "    time_coords = ds_test.time_sentinel_2_l2a.values\n",
    "    \n",
    "    # Mapping-Dictionary: Timestep-Index -> Monat (Name oder Zahl)\n",
    "    # Da wir t+1 vorhersagen, ist der Monat von 'target' der relevante\n",
    "    month_map = {i: pd.to_datetime(time_coords[i+1]).month_name() for i in range(len(time_coords)-1)}\n",
    "    \n",
    "    df_plot = df_eval.copy()\n",
    "    df_plot['Month'] = df_plot['timestep'].map(month_map)\n",
    "    \n",
    "    # 2. RMSE pro Monat und LC-Klasse berechnen\n",
    "    def calc_rmse(group):\n",
    "        valid = group.dropna(subset=['target', 'preds'])\n",
    "        if len(valid) < 10: return np.nan # Ignoriere zu kleine Stichproben\n",
    "        return np.sqrt(mean_squared_error(valid['target'], valid['preds']))\n",
    "\n",
    "    heatmap_data = df_plot.groupby(['lc_class', 'Month']).apply(calc_rmse).unstack()\n",
    "    \n",
    "    # Monate sortieren (damit sie nicht alphabetisch Jan, Aug, Dec... sind)\n",
    "    month_order = ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "                   'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    existing_months = [m for m in month_order if m in heatmap_data.columns]\n",
    "    heatmap_data = heatmap_data[existing_months]\n",
    "\n",
    "    # 3. Plotten\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.heatmap(heatmap_data, annot=True, cmap='YlOrRd', fmt='.3f', cbar_kws={'label': 'RMSE'})\n",
    "    \n",
    "    plt.title('Modell-Fehler (RMSE) nach Vegetationstyp und Monat', fontsize=15)\n",
    "    plt.xlabel('Monat der Vorhersage', fontsize=12)\n",
    "    plt.ylabel('Landcover Klasse (ESA LC)', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "# Heatmap generieren\n",
    "plot_error_heatmap(df_eval, cubes[test_key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
